r= 1/length(Nsplit)){
require(glmnet)
require(hdi)
require(SIS)
require(scalreg)
n <- dim(X)[1]
p <- dim(X)[2]
n1 <- floor(sub.frac*n)
n0 <- n-floor(n1)
Pvec <- numeric(Nsplit)
for(i in 1:Nsplit){
# Devide sample into two parts
set.seed(seed+i)
S1 <- sample(1:n, n1, replace=FALSE)
X.sub <- X[S1,]
if(standardized){
X.sub <- scale(X.sub)
}
Y.sub <- Y[S1]
cvfit <- cv.glmnet(X.sub, Y.sub, intercept=FALSE)
cf <- as.numeric(coef(cvfit, s="lambda.min"))[-1]
cf_testset <- cf[G1]
# sort the coefficients
K <- min(1, length(G1) ) # only caputure the maximum coefs.
id_test.set <- order(abs(cf_testset), decreasing = T)[1:K]
test.set <- G1[id_test.set]
tsXid <- setdiff(1:n, S1)
Xts <- X[tsXid, ]; n0 <- nrow(Xts)
Yts <- Y[tsXid]
# score.nodewiselasso = getFromNamespace("score.nodewiselasso", "hdi")
# node <- score.nodewiselasso(Xts, wantTheta=TRUE, verbose=FALSE, lambdaseq="quantile",
#                             parallel=FALSE, ncores=2, oldschool = FALSE, lambdatuningfactor = 1)
# Theta <- node$out
Theta_index <- getTheta(Xts, index_set = test.set)
Gram<- t(Xts)%*%Xts/n0
sreg <- scalreg::scalreg(Xts,Yts)
beta.hat <- sreg$coefficients
sigma.sq <- sum((Yts-Xts%*%beta.hat)^2)/(n0-sum(abs(beta.hat)>0))
index <- test.set
# Omega <- (t(Theta[,index])%*%Gram%*%Theta[,index])*sigma.sq
# beta.db <- beta.hat[index]+Theta[index,]%*%t(Xts)%*%(Yts-Xts%*%beta.hat)/n0
Omega <- (t(Theta_index)%*%Gram%*%Theta_index)*sigma.sq
beta.db <- beta.hat[index]+t(Theta_index)%*%t(Xts)%*%(Yts-Xts%*%beta.hat)/n0
T1 <- n0 * beta.db^2 / Omega;
Pvec[i] <-  1- pchisq(T1, 1)
}
nr <- length(r)
# reject <- numeric(nr)
# for(i in 1:nr){
#   gamma <- alpha*r[i]
#   if(mean(Pvec <= gamma) >= r[i]){
#     reject[i] <- 1
#   }
# }
Pvec <- p.adjust(Pvec, method="BH")
gamma <- alpha
reject <- 0
if(mean(Pvec <= gamma) >= 1/Nsplit){
reject <- 1
}
adj.pval <- min(Pvec)
res <- c('reject_status'=reject,   'adjusted_p-value'=adj.pval)
return(res)
}
n <- 100; p <- 20;i <- 1
s0 <- 5 # First five components are nonzeros
rho <- 1;
dat1 <- gendata_Reg(n, p, s0, seed=i, rho)
# ex1: H01 is false
MultiRegMax(dat1$X, dat1$Y, 1:p)
# ex1: H01 is true
MultiRegMax(dat1$X, dat1$Y, p)
library(TOSI)
### Example
n <- 100; p <- 20;i <- 1
s0 <- 5 # First five components are nonzeros
rho <- 1;
dat1 <- gendata_Reg(n, p, s0, seed=i, rho)
# ex1: H01 is false
MultiRegMax(dat1$X, dat1$Y, 1:p)
# ex1: H01 is true
MultiRegMax(dat1$X, dat1$Y, p)
rm(MultiRegMax)
n <- 100; p <- 20;i <- 1
s0 <- 5 # First five components are nonzeros
rho <- 1;
dat1 <- gendata_Reg(n, p, s0, seed=i, rho)
# ex1: H01 is false
MultiRegMax(dat1$X, dat1$Y, 1:p)
# ex1: H01 is true
MultiRegMax(dat1$X, dat1$Y, p)
res <-  MultiRegMax(dat1$X, dat1$Y, p)
res[1] <- as.integer(res[1])
res
res[1] <- TRUE
res
library(TOSI)
cov
### Example
n <- 100; p <- 20;i <- 1
s0 <- 5 # First five components are nonzeros
rho <- 1;
dat1 <- gendata_Reg(n, p, s0, seed=i, rho)
# ex1: H01 is false
MultiRegMin(dat1$X, dat1$Y, 1:s0)
# ex1: H01 is true
MultiRegMin(dat1$X, dat1$Y, p)
indvec2matFun
?indvec2matFun
library(TOSI)
library(TOSI)
example("MeanMax")
MeanMax
MeanMax <- function(X, test.set, Nsplit = 1, alpha=0.05,frac.size=0.5, standardized=F){
## Conservative inference by combing p-values based on quantile.
n <- nrow(X)
ns <- round(n*frac.size)
Pvec <- numeric(Nsplit)
for(im in 1: Nsplit){
set.seed(im)
ids <- sample(n, ns)
hmu <- colMeans(X[ids,])
abs_muG <- abs(hmu[test.set])
if(standardized){
std <- apply(as.matrix(X[ids, test.set], ncol=length(test.set)), 2, sd)
abs_muG <- abs_muG / std
}
K <- min(1, length(test.set))
id1 <- order(abs_muG, decreasing = T)[1:K]
test.set1 <- test.set[id1]
its <- setdiff(1:n, ids)
n0 <- length(its)
hmu <- mean(X[its, test.set1])
hsd <- sd(X[its, test.set])
T1 <- sqrt(n0) * abs(hmu / hsd)
Pvec[im] <- 2*(1- pnorm(T1))
if(Nsplit==1){
maxC1 <- qchisq(1-alpha, 1)
T1 <- n0 * hmu^2/ hsigma2
PV <-  1- pchisq(T1, 1)
res <- c(maxC1, T1, T1 > maxC1, PV)
names(res) <- c('CriticalValue', 'TestStatistic', 'reject_status', 'p-value')
return(res)
}
}
Pvec <- p.adjust(Pvec, method="BH")
gamma <- alpha
reject <- 0
if(mean(Pvec <= gamma) >= 1/Nsplit){
reject <- 1
}
adj.pval <- min(Pvec)
res <- c('reject_status'=reject,   'adjusted_p-value'=adj.pval)
return(res)
}
MeanMin <- function(X, test.set, Nsplit = 1, alpha=0.05,frac.size=0.5, standardized=F){
## Conservative inference by combing p-values based on quantile.
n <- nrow(X)
ns <- round(n*frac.size)
Pvec <- numeric(Nsplit)
for(im in 1: Nsplit){
set.seed(im)
ids <- sample(n, ns)
hmu <- colMeans(X[ids,])
abs_muG <- abs(hmu[test.set])
if(standardized){
std <- apply(as.matrix(X[ids, test.set], ncol=length(test.set)), 2, sd)
abs_muG <- abs_muG / std
}
K <- min(1, length(test.set))
id1 <- order(abs_muG, decreasing = F)[1:K]
test.set1 <- test.set[id1]
its <- setdiff(1:n, ids)
n0 <- length(its)
hmu <- mean(X[its, test.set1])
hsd <- sd(X[its, test.set])
T1 <- sqrt(n0) * abs(hmu / hsd)
Pvec[im] <-  2*(1- pnorm(T1))
if(Nsplit==1){
maxC1 <- qchisq(1-alpha, 1)
T1 <- n0 * hmu^2/ hsigma2
PV <-  1- pchisq(T1, 1)
res <- c(maxC1, T1, T1 > maxC1, PV)
names(res) <- c('CriticalValue', 'TestStatistic', 'reject_status', 'p-value')
return(res)
}
}
Pvec <- p.adjust(Pvec, method="BH")
gamma <- alpha
reject <- 0
if(mean(Pvec <= gamma) >= 1/Nsplit){
reject <- 1
}
adj.pval <- min(Pvec)
res <- c('reject_status'=reject,   'adjusted_p-value'=adj.pval)
return(res)
}
n <- 100; p <- 100;i <- 1
s0 <- 5 # First five components are nonzeros
rho <- 1; tau <- 1;
dat1 <- gendata_Mean(n, p, s0, seed=i, rho, tau)
# ex1: H01 is false
MeanMax(dat1$X, 1:p)
# ex1: H01 is true
MeanMax(dat1$X, p)
MeanMax <- function(X, test.set, Nsplit = 1, alpha=0.05,frac.size=0.5, standardized=F){
## Conservative inference by combing p-values based on quantile.
n <- nrow(X)
ns <- round(n*frac.size)
Pvec <- numeric(Nsplit)
for(im in 1: Nsplit){
set.seed(im)
ids <- sample(n, ns)
hmu <- colMeans(X[ids,])
abs_muG <- abs(hmu[test.set])
if(standardized){
std <- apply(as.matrix(X[ids, test.set], ncol=length(test.set)), 2, sd)
abs_muG <- abs_muG / std
}
K <- min(1, length(test.set))
id1 <- order(abs_muG, decreasing = T)[1:K]
test.set1 <- test.set[id1]
its <- setdiff(1:n, ids)
n0 <- length(its)
hmu <- mean(X[its, test.set1])
hsd <- sd(X[its, test.set])
T1 <- sqrt(n0) * abs(hmu / hsd)
Pvec[im] <- 2*(1- pnorm(T1))
if(Nsplit==1){
maxC1 <- qchisq(1-alpha, 1)
T1 <- n0 * (hmu^2)/ (hsd^2)
PV <-  1- pchisq(T1, 1)
res <- c(maxC1, T1, T1 > maxC1, PV)
names(res) <- c('CriticalValue', 'TestStatistic', 'reject_status', 'p-value')
return(res)
}
}
Pvec <- p.adjust(Pvec, method="BH")
gamma <- alpha
reject <- 0
if(mean(Pvec <= gamma) >= 1/Nsplit){
reject <- 1
}
adj.pval <- min(Pvec)
res <- c('reject_status'=reject,   'adjusted_p-value'=adj.pval)
return(res)
}
n <- 100; p <- 100;i <- 1
s0 <- 5 # First five components are nonzeros
rho <- 1; tau <- 1;
dat1 <- gendata_Mean(n, p, s0, seed=i, rho, tau)
# ex1: H01 is false
MeanMax(dat1$X, 1:p)
# ex1: H01 is true
MeanMax(dat1$X, p)
MeanMax(dat1$X, 1:p, Nsplit=5)
MeanMax(dat1$X, p, Nsplit=5)
n <- 100; p <- 100; i <- 2
s0 <- 5 # First five components are nonzeros
rho <- 5; tau <- 1;
dat1 <- gendata_Mean(n, p, s0, seed=i, rho, tau)
# ex1: H01 is false
MeanMin(dat1$X, 1:s0)
# ex1: H01 is true
MeanMin(dat1$X, 1:p)
MeanMin <- function(X, test.set, Nsplit = 1, alpha=0.05,frac.size=0.5, standardized=F){
## Conservative inference by combing p-values based on quantile.
n <- nrow(X)
ns <- round(n*frac.size)
Pvec <- numeric(Nsplit)
for(im in 1: Nsplit){
set.seed(im)
ids <- sample(n, ns)
hmu <- colMeans(X[ids,])
abs_muG <- abs(hmu[test.set])
if(standardized){
std <- apply(as.matrix(X[ids, test.set], ncol=length(test.set)), 2, sd)
abs_muG <- abs_muG / std
}
K <- min(1, length(test.set))
id1 <- order(abs_muG, decreasing = F)[1:K]
test.set1 <- test.set[id1]
its <- setdiff(1:n, ids)
n0 <- length(its)
hmu <- mean(X[its, test.set1])
hsd <- sd(X[its, test.set])
T1 <- sqrt(n0) * abs(hmu / hsd)
Pvec[im] <-  2*(1- pnorm(T1))
if(Nsplit==1){
maxC1 <- qchisq(1-alpha, 1)
T1 <- n0 * (hmu^2)/ (hsd^2)
PV <-  1- pchisq(T1, 1)
res <- c(maxC1, T1, T1 > maxC1, PV)
names(res) <- c('CriticalValue', 'TestStatistic', 'reject_status', 'p-value')
return(res)
}
}
Pvec <- p.adjust(Pvec, method="BH")
gamma <- alpha
reject <- 0
if(mean(Pvec <= gamma) >= 1/Nsplit){
reject <- 1
}
adj.pval <- min(Pvec)
res <- c('reject_status'=reject,   'adjusted_p-value'=adj.pval)
return(res)
}
n <- 100; p <- 100; i <- 2
s0 <- 5 # First five components are nonzeros
rho <- 5; tau <- 1;
dat1 <- gendata_Mean(n, p, s0, seed=i, rho, tau)
# ex1: H01 is false
MeanMin(dat1$X, 1:s0)
# ex1: H01 is true
MeanMin(dat1$X, 1:p)
n <- 100; p <- 100; i <- 2
s0 <- 5 # First five components are nonzeros
rho <- 2; tau <- 1;
dat1 <- gendata_Mean(n, p, s0, seed=i, rho, tau)
# ex1: H01 is false
MeanMin(dat1$X, 1:s0)
MeanMin(dat1$X, 1:s0, Nsplit=5)
# ex1: H01 is true
MeanMin(dat1$X, 1:p)
MeanMin(dat1$X, 1:p, Nsplit=5)
### Example
n <- 100; p <- 100; i <- 1
s0 <- 5 # First five components are nonzeros
rho <- 4; tau <- 1;
dat1 <- gendata_Mean(n, p, s0, seed=i, rho, tau)
# ex1: H01 is false
MeanMin(dat1$X, 1:s0)
MeanMin(dat1$X, 1:s0, Nsplit=5)
# ex1: H01 is true
MeanMin(dat1$X, 1:p)
MeanMin(dat1$X, 1:p, Nsplit=5)
library(TOSI)
dat <- gendata_Fac(n = 300, p = 500)
res <- Factorm(dat$X)
X <- dat$X
# ex1: H01 is false
G2 <- 1:200; # all are nonzero loading vectors
FacRowMinST(X, G2=G2, alpha=0.05, sub.frac=0.5)
# ex2: H01 is true
G2 <- 1:500 # all are zero loading vectors
FacRowMinST(X, G2=G2, alpha=0.05, sub.frac=0.5)
gendata_Fac
FacRowMinST(X, q= 6, G2=G2, alpha=0.05, sub.frac=0.5)
FacRowMinST(X, q= 5, G2=G2, alpha=0.05, sub.frac=0.5)
FacRowMinST(X, q= 7, G2=G2, alpha=0.05, sub.frac=0.5)
example("FacRowMaxST")
library(TOSI)
ccorFun
?Factorm
?bic.spfac
datlist1 <- gendata_Fac(n= 100, p = 500)
X <- datlist1$X
spfac <- gsspFactorm(X, q=NULL)
assessBsFun(spfac$sphB, datlist1$B0)
biclist <- bic.spfac(datlist1$X, c2.max=20,nlamb1 = 10)
plot(biclist$bic1[,2:3], type='o')
plot(biclist$bic2[,2:3], type='o')
spfac <- gsspFactorm(X, q=NULL,biclist$lambda1.min, biclist$lambda2.min)
assessBsFun(spfac$sphB, datlist1$B0)
?gsspFactorm
example("assessBFun")
?assessBFun
dat <- gendata_Fac(n = 300, p = 500)
res <- gsspFactorm(dat$X)
ccorFun(res$hH, dat$H0)
example("cv.spfac")
example("Factorm")
example("gendata_Fac")
example("gendata_Mean")
example("gendata_Reg")
example("gsspFactorm")
example("MeanMax")
example("MeanMin")
library(TOSI)
example("RegMax")
example("RegMin")
example("FacRowMaxST")
library(TOSI)
n <- 50; p <- 20;i <- 1
s0 <- 5 # First five components are nonzeros
rho <- 1;
dat1 <- gendata_Reg(n, p, s0, seed=i, rho)
# ex1: H01 is false
RegMax(dat1$X, dat1$Y, 1:p)
# ex1: H01 is true
RegMax(dat1$X, dat1$Y, p)
system.time({})
system.time({datlist1 <- gendata_Fac(n= 100, p = 500)
X <- datlist1$X
spfac <- gsspFactorm(X, q=NULL) # use default values for lambda's.
assessBsFun(spfac$sphB, datlist1$B0)
biclist <- bic.spfac(datlist1$X, c2.max=20,nlamb1 = 10) # # select lambda's values using BIC.
plot(biclist$bic1[,2:3], type='o')
plot(biclist$bic2[,2:3], type='o')
spfac <- gsspFactorm(X, q=NULL,biclist$lambda1.min, biclist$lambda2.min)
assessBsFun(spfac$sphB, datlist1$B0)})
system.time({dat <- gendata_Fac(n = 300, p = 500)
res <- gsspFactorm(dat$X)
ccorFun(res$hH, dat$H0) # the smallest canonical correlation
## comparison of l2 norm
par(mar=c(5,5,2,2), mfrow=c(1,2))
plot(rowSums(dat$B0^2), type='o', ylab='l2B', main='True')
l2B <- rowSums(res$sphB^2)
plot(l2B, type='o', main='Est.')
Bind <- ifelse(dat$B0==0, 0, 1)
hBind <- ifelse(res$sphB==0, 0, 1)
## Select good penalty parameters
dat <- gendata_Fac(n = 300, p = 200)
res <- gsspFactorm(dat$X, lambda1=0.04*nrow(dat$X)^(1/4) ,lambda2=1*nrow(dat$X)^(1/4))
ccorFun(res$hH, dat$H0) # the smallest canonical correlation
## comparison of l2 norm
plot(rowSums(dat$B0^2), type='o', ylab='l2B', main='True')
l2B <- rowSums(res$sphB^2)
plot(l2B, type='o', main='Est.')
## comparison of structure of loading matrix
Bind <- ifelse(dat$B0==0, 0, 1)
hBind <- ifelse(res$sphB==0, 0, 1)
})
library(TOSI)
hdi::score.getZforlambda
hdi:::score.getZforlambda
library(hdi)
?score.getZforlambda
library(TOSI)
library(TOSI)
library(TOSI)
example("assessBsFun")
example("bic.spfac")
example("ccorFun")
example("cv.spfac")
example("Factorm")
example("gendata_Fac")
example("gendata_Mean")
example("gendata_Reg")
example("gsspFactorm")
example("MeanMax")
example("MeanMin")
example("RegMax")
example("RegMin")
example("FacRowMaxST")
example("FacRowMinST")
library(TOSI)
library(TOSI)
FALSE
FALSE
dat <- gendata_Fac(n = 300, p = 500)
res <- gsspFactorm(dat$X)
ccorFun(res$hH, dat$H0) # the smallest canonical correlation
## comparison of l2 norm
oldpar <- par(mar = c(5, 5, 2, 2), mfrow = c(1, 2))
plot(rowSums(dat$B0^2), type='o', ylab='l2B', main='True')
l2B <- rowSums(res$sphB^2)
plot(l2B, type='o', main='Est.')
Bind <- ifelse(dat$B0==0, 0, 1)
hBind <- ifelse(res$sphB==0, 0, 1)
## Select good penalty parameters
dat <- gendata_Fac(n = 300, p = 200)
res <- gsspFactorm(dat$X, lambda1=0.04*nrow(dat$X)^(1/4) ,lambda2=1*nrow(dat$X)^(1/4))
ccorFun(res$hH, dat$H0) # the smallest canonical correlation
## comparison of l2 norm
plot(rowSums(dat$B0^2), type='o', ylab='l2B', main='True')
l2B <- rowSums(res$sphB^2)
plot(l2B, type='o', main='Est.')
## comparison of structure of loading matrix
Bind <- ifelse(dat$B0==0, 0, 1)
hBind <- ifelse(res$sphB==0, 0, 1)
par(oldpar)
library(TOSI)
dat <- gendata_Fac(n = 300, p = 500)
res <- gsspFactorm(dat$X)
ccorFun(res$hH, dat$H0) # the smallest canonical correlation
## comparison of l2 norm
oldpar <- par(mar = c(5, 5, 2, 2), mfrow = c(1, 2))
plot(rowSums(dat$B0^2), type='o', ylab='l2B', main='True')
l2B <- rowSums(res$sphB^2)
plot(l2B, type='o', main='Est.')
Bind <- ifelse(dat$B0==0, 0, 1)
hBind <- ifelse(res$sphB==0, 0, 1)
## Select good penalty parameters
dat <- gendata_Fac(n = 300, p = 200)
res <- gsspFactorm(dat$X, lambda1=0.04*nrow(dat$X)^(1/4) ,lambda2=1*nrow(dat$X)^(1/4))
ccorFun(res$hH, dat$H0) # the smallest canonical correlation
## comparison of l2 norm
plot(rowSums(dat$B0^2), type='o', ylab='l2B', main='True')
l2B <- rowSums(res$sphB^2)
plot(l2B, type='o', main='Est.')
## comparison of structure of loading matrix
Bind <- ifelse(dat$B0==0, 0, 1)
hBind <- ifelse(res$sphB==0, 0, 1)
par(oldpar)
FALSE
library(TOSI)
library(TOSI)
datlist1 <- gendata_Fac(n= 100, p = 500)
X <- datlist1$X
spfac <- gsspFactorm(X, q=NULL) # use default values for lambda's.
assessBsFun(spfac$sphB, datlist1$B0)
biclist <- bic.spfac(datlist1$X, c2.max=20,nlamb1 = 10) # # select lambda's values using BIC.
library(TOSI)
example("bic.spfac")
datlist1 <- gendata_Fac(n= 100, p = 500)
X <- datlist1$X
spfac <- gsspFactorm(X, q=NULL) # use default values for lambda's.
assessBsFun(spfac$sphB, datlist1$B0)
biclist <- bic.spfac(datlist1$X, c2.max=20,nlamb1 = 10) # # select lambda's values using BIC.
biclist
library(TOSI)
